[
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Linear\/shape"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "shape"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Step\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ModuleInfo\/init(wrappedValue:key:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(wrappedValue:key:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/PReLU\/init(count:value:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(count:value:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/noUnusedKeys"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Check that all keys are used.  This is useful to ensure that e.g. all loaded parameters are used – there are no names that don’t match. ",
    "summary" : "Check that all keys are used.  This is useful to ensure that e.g. all loaded parameters are used – there are no names that don’t match.",
    "title" : "noUnusedKeys"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Mish\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SequentialBuilder\/buildPartialBlock(first:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "buildPartialBlock(first:)"
  },
  {
    "headings" : [
      "Return Value",
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/filterMap(filter:map:isLeaf:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Recursively filter and map the contents of the module and its children and produce a NestedDictionary with the results.  filter function that determines if the (Module, Key, Item) tuple should be examined Transformation of the values.  By default this is identity but the caller can transform to other types, etc.  See mapParameters(map:) and others for helper functions that can assist with common types. closure that determines if a value is a leaf or not. Return Value NestedDictionary matching the structure with mapped values. Discussion Traverses the ModuleItems produced by items() and filters and maps their contents.  For each item in the ModuleItems this will call the filter to determine if it should be included.  There are a number of predefined filters available, see Module Filter and Map Functions.  filterAll will accept all values while filterValidParameters will only examine structure and parameters. The map function transforms the visited values.  By default it is identity and will just return the ModuleItem directly.  There are a number of helper functions like mapParameters(map:) and mapModule(map:) that can help deal with types like MLXArray or Module.  For example:  The isLeaf function is called to determine if the value should be transformed via the map or if the structure should be traversed.  For example this will collect the leaf modules:  See Also Module Filter and Map Functions parameters() mapParameters(map:isLeaf:) modules() items()",
    "summary" : "Recursively filter and map the contents of the module and its children and produce a NestedDictionary with the results.",
    "title" : "filterMap(filter:map:isLeaf:)"
  },
  {
    "headings" : [
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/isLeafModuleNoChildren"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Leaf filter that will stop at ModuleValue.module(_:) if they have no child modules and recurse into all other structure.  See Also Module Filter and Map Functions filterMap(filter:map:isLeaf:)",
    "summary" : "Leaf filter that will stop at ModuleValue.module(_:) if they have no child modules and recurse into all other structure.",
    "title" : "isLeafModuleNoChildren"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ModuleValue"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "A single value from Module.  Overview This is typically produced from items() or indirectly via filterMap(filter:map:isLeaf:). See Also items() filterMap(filter:map:isLeaf:) ModuleItems ModuleItem",
    "summary" : "A single value from Module.",
    "title" : "ModuleValue"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/HardSwish\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ParameterInfo\/wrappedValue"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "wrappedValue"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ReLU"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Rectified Linear Unit.  Overview This is:  See Also Activation Functions and Layers relu(_:)",
    "summary" : "Applies the Rectified Linear Unit.",
    "title" : "ReLU"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LogSoftMax\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/CELU"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Continuously Differentiable Exponential Linear Unit.  Overview This is:  See Also Activation Functions and Layers celu(_:alpha:)",
    "summary" : "Applies the Continuously Differentiable Exponential Linear Unit.",
    "title" : "CELU"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/GELU\/Approximation\/!=(_:_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from Equatable.!=(_:_:). ",
    "summary" : "Inherited from Equatable.!=(_:_:).",
    "title" : "!=(_:_:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/HardSwish"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the hardswish function, element-wise  Overview This is:  See Also Activation Functions and Layers hardSwish(_:)",
    "summary" : "Applies the hardswish function, element-wise",
    "title" : "HardSwish"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Mish"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Mish function, element-wise.  Overview Mish: A Self Regularized Non-Monotonic Neural Activation Function. Reference: https:\/\/arxiv.org\/abs\/1908.08681 This is:  See Also Activation Functions and Layers mish(_:)",
    "summary" : "Applies the Mish function, element-wise.",
    "title" : "Mish"
  },
  {
    "headings" : [
      "Return Value",
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/mapParameters(map:isLeaf:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Apply a map to all parameters (ModuleValue.parameters(_:)) in the module and its children.  closure that transforms MLXArray into Result type or nil optional leaf function Return Value NestedDictionary of mapped results Discussion For example:  This is equivalent to:  See Also Module Filter and Map Functions mapParameters(map:)",
    "summary" : "Apply a map to all parameters (ModuleValue.parameters(_:)) in the module and its children.",
    "title" : "mapParameters(map:isLeaf:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Tanh\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/items()"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Return a NestedDictionary structure of ModuleItem representing the ivars of the Module instance.  Discussion This is typically not used directly – it is part of the implementation of filterMap(filter:map:isLeaf:) and update(parameters:) for example. Subclasses could potentially override this to provide custom introspection.",
    "summary" : "Return a NestedDictionary structure of ModuleItem representing the ivars of the Module instance.",
    "title" : "items()"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/GLU\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/QuantizedLinear\/unfreeze(recursive:keys:strict:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from Module.unfreeze(recursive:keys:strict:). ",
    "summary" : "Inherited from Module.unfreeze(recursive:keys:strict:).",
    "title" : "unfreeze(recursive:keys:strict:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LossReduction\/hash(into:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from RawRepresentable.hash(into:). ",
    "summary" : "Inherited from RawRepresentable.hash(into:).",
    "title" : "hash(into:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/init()"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from OptionSet.init(). ",
    "summary" : "Inherited from OptionSet.init().",
    "title" : "init()"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/GELU\/Approximation\/fast"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "See geluFastApproximate(_:) ",
    "summary" : "See geluFastApproximate(_:)",
    "title" : "GELU.Approximation.fast"
  },
  {
    "headings" : [
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Conv2d"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies a 2-dimensional convolution over the multi-channel input image.  See Also Conv1d init(inputChannels:outputChannels:kernelSize:stride:padding:bias:)",
    "summary" : "Applies a 2-dimensional convolution over the multi-channel input image.",
    "title" : "Conv2d"
  },
  {
    "headings" : [
      "Return Value",
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/valueAndGrad(model:_:)-12a2c"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Transform the passed function f(Model, MLXArray, MLXArray) to a function that computes the gradients of f with regard to the model’s trainable parameters and also its value.  model to apply parameters to function to compute the gradients for Return Value function that returns the value of f() and the gradient of the parameters of the model Discussion For example:  See Also Training a Model",
    "summary" : "Transform the passed function f(Model, MLXArray, MLXArray) to a function that computes the gradients of f with regard to the model’s trainable parameters and also its value.",
    "title" : "valueAndGrad(model:_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Identity\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/filterTrainableParameters"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Filter that will accept all structure (.array and .dictionary) and ModuleValue.parameters(_:) or ModuleValue.module(_:) that are not in the noGrad set.  See Also Module Filter and Map Functions freeze(recursive:keys:strict:) filterValidParameters filterLocalParameters",
    "summary" : "Filter that will accept all structure (.array and .dictionary) and ModuleValue.parameters(_:) or ModuleValue.module(_:) that are not in the noGrad set.",
    "title" : "filterTrainableParameters"
  },
  {
    "headings" : [
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/filterValidChild"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Filter that will accept all structure (.array and .dictionary) and ModuleValue.module(_:).  See Also Module Filter and Map Functions",
    "summary" : "Filter that will accept all structure (.array and .dictionary) and ModuleValue.module(_:).",
    "title" : "filterValidChild"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ModuleInfo\/wrappedValue"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "wrappedValue"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LossReduction\/mean"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "take the mean of the loss. This produces a a scalar array ",
    "summary" : "take the mean of the loss. This produces a a scalar array",
    "title" : "LossReduction.mean"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/softPlus(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Softplus function.  Discussion This is:  See Also Activation Functions and Layers SoftPlus",
    "summary" : "Applies the Softplus function.",
    "title" : "softPlus(_:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/silu(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Sigmoid Linear Unit. Also known as Swish.  Discussion This is:  See Also Activation Functions and Layers SiLU",
    "summary" : "Applies the Sigmoid Linear Unit. Also known as Swish.",
    "title" : "silu(_:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Base class for building neural networks with MLX.  Overview All the layers provided in Layers subclass this class and your models should do the same. A Module can contain other Module instances or MLXArray instances in structures of Array and Dictionary. The Module then allows recursively extracting all the MLXArray instances using parameters() In addition, the Module has the concept of trainable and non trainable parameters (called “frozen”). When using valueAndGrad() or grad() the gradients are returned only with respect to the trainable parameters. All arrays in a module are trainable unless they are added in the “frozen” set by calling freeze(recursive:keys:strict:)  Please read Creating Modules for more information about implementing custom layers including how to override the module and parameter keys and allowing dynamic updates of the module structure to occur via update(modules:verify:). See Also Creating Modules",
    "summary" : "Base class for building neural networks with MLX.",
    "title" : "Module"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/GELU\/Approximation\/none"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "See gelu(_:) ",
    "summary" : "See gelu(_:)",
    "title" : "GELU.Approximation.none"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Dropout3d\/init(p:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(p:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/elu(_:alpha:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Exponential Linear Unit.  Discussion This is:  See Also Activation Functions and Layers",
    "summary" : "Applies the Exponential Linear Unit.",
    "title" : "elu(_:alpha:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/update(parameters:verify:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Replace the parameters of this Module with the provided parameters.  replacement parameters in the same format that parameters() or mapParameters(map:isLeaf:) provides options for verifying parameters Discussion This will replace the parameters in the Module recursively with the given ModuleParameters structure.  For example:  The parameters need not provide all values in the model – any omitted values will be unchanged. The apply(filter:map:) can be used for similar purposes to apply changes in-place. See Also Creating Modules update(parameters:) apply(filter:map:) parameters() mapParameters(map:isLeaf:) update(modules:verify:)",
    "summary" : "Replace the parameters of this Module with the provided parameters.",
    "title" : "update(parameters:verify:)"
  },
  {
    "headings" : [
      "Return Value",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/nllLoss(inputs:targets:axis:reduction:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Computes the negative log likelihood loss.  predicted distribution in log space the target values distribution axis reduction type Return Value computed NLL loss See Also Loss Functions",
    "summary" : "Computes the negative log likelihood loss.",
    "title" : "nllLoss(inputs:targets:axis:reduction:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Sequential\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SoftMax\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/CELU\/init(alpha:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(alpha:)"
  },
  {
    "headings" : [
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/namedModules()"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Return a flat array of all the Module in the instance (including self) with their keys.  See Also modules() children() leafModules()",
    "summary" : "Return a flat array of all the Module in the instance (including self) with their keys.",
    "title" : "namedModules()"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/MultiHeadAttention\/callAsFunction(_:keys:values:mask:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "callAsFunction(_:keys:values:mask:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/MultiHeadAttention\/createAdditiveCausalMask(_:dtype:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "createAdditiveCausalMask(_:dtype:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/update(with:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from OptionSet.update(with:). ",
    "summary" : "Inherited from OptionSet.update(with:).",
    "title" : "update(with:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SequentialBuilder\/buildArray(_:)-j82o"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "buildArray(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Dropout\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [
      "Overview"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SequentialBuilder"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "A way to build Sequential.  Overview See ``Sequential\/init(layers:)-43yu",
    "summary" : "A way to build Sequential.",
    "title" : "SequentialBuilder"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Conv1d\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Bilinear\/callAsFunction(_:_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "callAsFunction(_:_:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/geluApproximate(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "An approximation to Gaussian Error Linear Unit.  Discussion This is:  See Also Activation Functions and Layers GELU gelu(_:) geluFastApproximate(_:)",
    "summary" : "An approximation to Gaussian Error Linear Unit.",
    "title" : "geluApproximate(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Linear\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/subtract(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from SetAlgebra.subtract(_:). ",
    "summary" : "Inherited from SetAlgebra.subtract(_:).",
    "title" : "subtract(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "article",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/SetAlgebra-Implementations"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "",
    "summary" : "",
    "title" : "SetAlgebra Implementations"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/contains(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from OptionSet.contains(_:). ",
    "summary" : "Inherited from OptionSet.contains(_:).",
    "title" : "contains(_:)"
  },
  {
    "headings" : [
      "Return Value",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/valueAndGrad(model:_:)-548r7"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Transform the passed function f(Model, [MLXArray]) to a function that computes the gradients of f with regard to the model’s trainable parameters and also its value.  model to apply parameters to function to compute the gradients for Return Value function that returns the value of f() and the gradient of the parameters of the model See Also valueAndGrad(model:_:) Training a Model",
    "summary" : "Transform the passed function f(Model, [MLXArray]) to a function that computes the gradients of f with regard to the model’s trainable parameters and also its value.",
    "title" : "valueAndGrad(model:_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SoftSign\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Bilinear"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies a bilinear transformation to the inputs.  Overview Concretely:  where w has shape [outputDimensions, inputDimensions2, inputDimensions1] and b has shape [outputDimensions]. The values are initialized from the uniform distribution:  See Also Creating Modules Linear",
    "summary" : "Applies a bilinear transformation to the inputs.",
    "title" : "Bilinear"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/logSoftMax(_:axis:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Log Softmax function.  Discussion This is:  See Also Activation Functions and Layers LogSoftMax",
    "summary" : "Applies the Log Softmax function.",
    "title" : "logSoftMax(_:axis:)"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ModuleValue\/module(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "A module value.  Discussion From code: ",
    "summary" : "A module value.",
    "title" : "ModuleValue.module(_:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/GELU"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Gaussian Error Linear Units function.  Overview There are three variations: GELU.Approximation.none GELU.Approximation.precise GELU.Approximation.fast See Also Activation Functions and Layers gelu(_:) geluApproximate(_:) geluFastApproximate(_:)",
    "summary" : "Applies the Gaussian Error Linear Units function.",
    "title" : "GELU"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/union(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from OptionSet.union(_:). ",
    "summary" : "Inherited from OptionSet.union(_:).",
    "title" : "union(_:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Relu6"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Rectified Linear Unit 6.  Overview This is:  See Also Activation Functions and Layers relu6(_:)",
    "summary" : "Applies the Rectified Linear Unit 6.",
    "title" : "Relu6"
  },
  {
    "headings" : [

    ],
    "kind" : "article",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/losses"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Built-in loss functions",
    "summary" : "Built-in loss functions",
    "title" : "Loss Functions"
  },
  {
    "headings" : [
      "Overview"
    ],
    "kind" : "article",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/training"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "A model training loop. Overview The model traing loop in MLX consists of: defining a model defining a loss function that measures the distance between predicted and expected values using the valueAndGrad() function to create a new function to compute the gradient presenting training data and expected values to the model, measuring the loss and computing the gradient using an optimizer to apply the gradient to the model parameters see more about optimizers in MLXOptimizers repeat Here is an example showing a simple model that learns a linear function, literally f(x) = mx + b.  This model is simpler than most, but it is easy to understand and see how it works.  Next we define a loss function – there are a number of Loss Functions available to use.  I chose one that accepted simple predictions and targets:  Now we create the model, build the lg (loss and gradient) function and create the optimizer.  We could define any f(x) – I will use a simple one that the model should be able to match very closely.  Now we run the training loop for a number of epochs.  In each epoch we produce training data (input x values) and expected values (just evaluate f(x)). From this we can evaluate the model and compute a loss and gradient. The gradients are given to the optimizer to update the model parameters. ",
    "summary" : "A model training loop.",
    "title" : "Training a Model"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LogSigmoid\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/init(rawValue:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from OptionSet.init(rawValue:). ",
    "summary" : "Inherited from OptionSet.init(rawValue:).",
    "title" : "init(rawValue:)"
  },
  {
    "headings" : [
      "Neural Networks",
      "The Module Class",
      "Parameters",
      "Updating the Parameters",
      "Inspecting Modules",
      "ModuleInfo and ParameterInfo",
      "Converting From Python"
    ],
    "kind" : "article",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/custom-layers"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Creating custom modules using MLXNN. Neural Networks Writing arbitrarily complex neural networks in MLX can be done using only MLXArray and valueAndGrad().  However, this requires the user to write again and again the same simple neural network operations as well as handle all the parameter state and initialization manually and explicitly. The MLXNN package solves this problem by providing an intuitive way of composing neural network layers, initializing their parameters, freezing them for finetuning and more. The Module Class The workhorse of any neural network library is the Module class. In MLX the Module class is a container of MLXArray or Module instances. Its main function is to provide a way to recursively access and update its parameters and those of its submodules. Creating a new Module subclass from scratch looks like this:  This will declare a FeedForward layer similar to the layer in the Mistral Example. This layer can be used:  See the Converting From Python section about other considerations when converting code. Parameters A parameter of a module is any public member of type MLXArray (its name should not start with _). It can be arbitrarily nested in other Module instances or [MLXArray] and [String:MLXArray]. parameters() can be used to extract a NestedDictionary (ModuleParameters) with all the parameters of a module and its submodules. A Module can also keep track of “frozen” parameters. See the freeze(recursive:keys:strict:) method for more details. These parameters will not be considered when computing gradients and updating weights via valueAndGrad(model:_:). See the ModuleInfo and ParameterInfo section for more information about using these in swift. Updating the Parameters MLX modules allow accessing and updating individual parameters. However, most times we need to update large subsets of a module’s parameters. This action is performed by update(parameters:verify:). See also Training a Model. Inspecting Modules The simplest way to see the model architecture is to print it. Following along with the above example, you can print the FeedForward with:  This will display:  To get more detailed information on the arrays in a Module you can use mapParameters(map:isLeaf:).  For example to see the shapes of all the parameters from above:  resulting in:  ModuleInfo and ParameterInfo The ModuleInfo and ParameterInfo provide two important features for module instance variables: both property wrappers allow replacement keys to be specified the ModuleInfo allows update(modules:verify:) to replace the module Replacement keys are important because many times models and weights are defined in terms of their python implementation.  For example here is a definition of a module:  The keys for modules and parameters are usually named after their instance variables, but feed_forward would not be a very Swifty variable name.  Instead we can use ModuleInfo to supply a replacement key:  All Linear modules should use a ModuleInfo so that quantize(model:groupSize:bits:predicate:) can replace them at runtime:  The ModuleInfo provides a hook for QuantizedLinear and update(modules:verify:) to replace the contents of w1, etc. with a new compatible Model after it is created. Note that MLXArray is settable without any ParameterInfo – it has an update() method. Converting From Python Consider this example from a Llama model:  The straightforward conversion might look like this:  Here is another example that has parameters (MLXArray) from the mlx.nn package (both sans documentation):  and the swift conversion: ",
    "summary" : "Creating custom modules using MLXNN.",
    "title" : "Creating Modules"
  },
  {
    "headings" : [
      "Return Value",
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/klDivLoss(inputs:targets:axis:reduction:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Computes the Kullback-Leibler divergence loss.  Log probabilities for the predicted distribution Log probabilities for the target distribution distribution axis reduction type Return Value computed Kullback-Leibler divergence loss Discussion Computes the following when the reduction: .none:  See Also Loss Functions",
    "summary" : "Computes the Kullback-Leibler divergence loss.",
    "title" : "klDivLoss(inputs:targets:axis:reduction:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Sequential\/init(layers:)-2rde0"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(layers:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/parameters()"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Return a NestedDictionary<String, MLXArray> for all parameters in the model (all layers). ",
    "summary" : "Return a NestedDictionary<String, MLXArray> for all parameters in the model (all layers).",
    "title" : "parameters()"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/formUnion(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from OptionSet.formUnion(_:). ",
    "summary" : "Inherited from OptionSet.formUnion(_:).",
    "title" : "formUnion(_:)"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Sequential\/init(layers:)-43yu"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "A convenient way to write code that builds a Sequential layer:  Discussion  produces: ",
    "summary" : "A convenient way to write code that builds a Sequential layer:",
    "title" : "init(layers:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/isSuperset(of:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from SetAlgebra.isSuperset(of:). ",
    "summary" : "Inherited from SetAlgebra.isSuperset(of:).",
    "title" : "isSuperset(of:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/relu(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Rectified Linear Unit.  Discussion This is:  See Also Activation Functions and Layers ReLU",
    "summary" : "Applies the Rectified Linear Unit.",
    "title" : "relu(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ModuleItems"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "NestedDictionary structure of ModuleValue from items() ",
    "summary" : "NestedDictionary structure of ModuleValue from items()",
    "title" : "ModuleItems"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SoftSign"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Softsign function.  Overview This is:  See Also Activation Functions and Layers softSign(_:)",
    "summary" : "Applies the Softsign function.",
    "title" : "SoftSign"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/update(modules:verify:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Replace the child modules of this Module with the provided replacements.  replacement modules in the same format as children() or leafModules() options for verifying parameters Discussion This will replace the parameters in the Module recursively with the given ModuleChilren structure.  For example this is typically called via a helper function:  Note that the modules being replace must use a ModuleInfo property wrapper – this provides the mechanism to update the values.  Also note that the replacement models must be assignable to the ivar’s type. For example:  Would be able to be replaced with quantize(model:groupSize:bits:predicate:). The modules need not provide all values in the model – any omitted values will be unchanged. See Also Creating Modules update(modules:) update(parameters:verify:) children() leafModules() quantize(model:groupSize:bits:predicate:)",
    "summary" : "Replace the child modules of this Module with the provided replacements.",
    "title" : "update(modules:verify:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Embedding\/describeExtra(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Describe the shape of the weight. ",
    "summary" : "Describe the shape of the weight.",
    "title" : "describeExtra(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ParameterInfo\/init(key:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(key:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LeakyReLU"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Leaky Rectified Linear Unit.  Overview This is:  See Also Activation Functions and Layers leakyRelu(_:negativeSlope:)",
    "summary" : "Applies the Leaky Rectified Linear Unit.",
    "title" : "LeakyReLU"
  },
  {
    "headings" : [
      "Overview",
      "Using In A Module",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Linear"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies an affine transformation to the input.  Overview Concretely:  where W has shape [inputDimensions, outputDimensions] and b has shape [outputDimensions]. The values are initialized from the uniform distribution:  Using In A Module Use @ModuleInfo with all your Linear module uses so that update(modules:verify:) can replace the modules, e.g. via quantize(model:groupSize:bits:predicate:). For example:  If a key is needed (to change the parameters key for parameters()) here is the way to initialize the ivar:  See Also Creating Modules QuantizedLinear Bilinear",
    "summary" : "Applies an affine transformation to the input.",
    "title" : "Linear"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SequentialBuilder\/buildEither(second:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "buildEither(second:)"
  },
  {
    "headings" : [
      "Overview"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Embedding"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Implements a simple lookup table that maps each input integer to a high-dimensional vector.  Overview Typically used to embed discrete tokens for processing by neural networks.",
    "summary" : "Implements a simple lookup table that maps each input integer to a high-dimensional vector.",
    "title" : "Embedding"
  },
  {
    "headings" : [
      "Overview"
    ],
    "kind" : "article",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/layers"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Built-in layers. Overview MLXNN provides a number of built-in layers that can be used to build models.\nSee also Activation Functions and Layers for Activation Layers and Creating Modules for examples of their use",
    "summary" : "Built-in layers.",
    "title" : "Layers"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/softMax(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Softmax function.  Discussion This is:  See Also Activation Functions and Layers SoftMax",
    "summary" : "Applies the Softmax function.",
    "title" : "softMax(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Bilinear\/init(_:_:_:bias:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(_:_:_:bias:)"
  },
  {
    "headings" : [
      "Return Value",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/cosineSimilarityLoss(x1:x2:axis:eps:reduction:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Computes the cosine similarity between the two inputs.  first array second array embedding axis minimum value of the denominator used for numerical stability reduction type Return Value computed cosine similarity loss See Also Loss Functions",
    "summary" : "Computes the cosine similarity between the two inputs.",
    "title" : "cosineSimilarityLoss(x1:x2:axis:eps:reduction:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/init(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from SetAlgebra.init(_:). ",
    "summary" : "Inherited from SetAlgebra.init(_:).",
    "title" : "init(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "article",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LossReduction\/Equatable-Implementations"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "",
    "summary" : "",
    "title" : "Equatable Implementations"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/all"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "all"
  },
  {
    "headings" : [
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/filterLocalParameters"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Filter that will accept all structure (.array and .dictionary) and ModuleValue.parameters(_:) without allowing recursion into sub-Modules (layers).  See Also Module Filter and Map Functions filterValidParameters filterTrainableParameters",
    "summary" : "Filter that will accept all structure (.array and .dictionary) and ModuleValue.parameters(_:) without allowing recursion into sub-Modules (layers).",
    "title" : "filterLocalParameters"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/QuantizedLinear\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/GELU\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/celu(_:alpha:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Continuously Differentiable Exponential Linear Unit.  Discussion This is:  See Also Activation Functions and Layers CELU",
    "summary" : "Applies the Continuously Differentiable Exponential Linear Unit.",
    "title" : "celu(_:alpha:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/noGrad"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "noGrad"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/isStrictSubset(of:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from SetAlgebra.isStrictSubset(of:). ",
    "summary" : "Inherited from SetAlgebra.isStrictSubset(of:).",
    "title" : "isStrictSubset(of:)"
  },
  {
    "headings" : [
      "Return Value",
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/smoothL1Loss(predictions:targets:beta:reduction:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Computes the smooth L1 loss.  predicted values ground truth values threshold after which the loss changes from the squared to the absolute difference reduction type Return Value computed smooth L1 loss Discussion The smooth L1 loss is a variant of the L1 loss which replaces the absolute difference with a squared difference when the absolute difference is less than beta. See Also Loss Functions",
    "summary" : "Computes the smooth L1 loss.",
    "title" : "smoothL1Loss(predictions:targets:beta:reduction:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Conv2d\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "article",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/GELU\/Approximation\/Equatable-Implementations"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "",
    "summary" : "",
    "title" : "Equatable Implementations"
  },
  {
    "headings" : [
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/isLeafModule"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Leaf filter that will stop at ModuleValue.module(_:) and recurse into all other structure.  See Also Module Filter and Map Functions filterMap(filter:map:isLeaf:)",
    "summary" : "Leaf filter that will stop at ModuleValue.module(_:) and recurse into all other structure.",
    "title" : "isLeafModule"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/RMSNorm\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ReLU\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ParameterInfo\/init(wrappedValue:key:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(wrappedValue:key:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LeakyReLU\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [
      "Overview"
    ],
    "kind" : "article",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/activations"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Built-in activation functions and layers. Overview MLXNN provides a number of activation functions and modules.  The modules simply wrap the functions, though some like GELU provide some settings that select between different functions.  Others, like CELU encapsulate parameters such as alpha.",
    "summary" : "Built-in activation functions and layers.",
    "title" : "Activation Functions and Layers"
  },
  {
    "headings" : [
      "Return Value",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/crossEntropy(logits:targets:weights:axis:labelSmoothing:reduction:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Computes the cross entropy loss.  unnormalized predicted logits target values, as class indices weights for each target axis over which to compute softmax label smoothing factor, range [0, 1) reduction type Return Value computed cross entropy loss See Also Loss Functions",
    "summary" : "Computes the cross entropy loss.",
    "title" : "crossEntropy(logits:targets:weights:axis:labelSmoothing:reduction:)"
  },
  {
    "headings" : [
      "Return Value",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/valueAndGrad(model:_:)-1w6x8"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Transform the passed function f(Model, MLXArray) to a function that computes the gradients of f with regard to the model’s trainable parameters and also its value.  model to apply parameters to function to compute the gradients for Return Value function that returns the value of f() and the gradient of the parameters of the model See Also valueAndGrad(model:_:) Training a Model",
    "summary" : "Transform the passed function f(Model, MLXArray) to a function that computes the gradients of f with regard to the model’s trainable parameters and also its value.",
    "title" : "valueAndGrad(model:_:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LogSigmoid"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Log Sigmoid function.  Overview This is:  See Also Activation Functions and Layers logSigmoid(_:)",
    "summary" : "Applies the Log Sigmoid function.",
    "title" : "LogSigmoid"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ModuleInfo\/init(key:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(key:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LossReduction\/hashValue"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from RawRepresentable.hashValue. ",
    "summary" : "Inherited from RawRepresentable.hashValue.",
    "title" : "hashValue"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/RoPE\/init(dimensions:traditional:base:scale:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Initialize RoPE.  The feature dimensions to be rotated. If the input feature is larger than dims then the rest is left unchanged If true choose the traditional implementation which is slightly less efficient The base used to compute angular frequency for each dimension in the positional encodings scale used to scale the positions",
    "summary" : "Initialize RoPE.",
    "title" : "init(dimensions:traditional:base:scale:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/mapOther(map:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Function that will turn a (Any) -> Result? into a function suitable for use in filterMap(filter:map:isLeaf:).  Discussion For example:  See Also Module Filter and Map Functions ModuleValue.other(_:) filterMap(filter:map:isLeaf:)",
    "summary" : "Function that will turn a (Any) -> Result? into a function suitable for use in filterMap(filter:map:isLeaf:).",
    "title" : "mapOther(map:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/GLU\/init(axis:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(axis:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/training"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "training"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/freeze(recursive:keys:strict:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Freeze the Module’s parameters or subset.  if true this will freeze the parameters of child Module recursively optional keys tofreezeunfreeze – if unspecified, will apply to all if true validate that the passed keys exist Discussion A frozen parameter does not compute gradients.  The function is idempotent – freezing a frozen model is a no-op. For example to only train the attention parameters from a Transformer:  See Also freeze(recursive:keys:) unfreeze(recursive:keys:strict:)",
    "summary" : "Freeze the Module’s parameters or subset.",
    "title" : "freeze(recursive:keys:strict:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/CELU\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LossReduction\/sum"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "take the sum of the loss.  This produces a a scalar array. ",
    "summary" : "take the sum of the loss.  This produces a a scalar array.",
    "title" : "LossReduction.sum"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Relu6\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Dropout"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Randomly zero a portion of the elements during training.  Overview The remaining elements are multiplied with 1 \/ (1-p) where p is the probability of zeroing an element. This is done so the expected value of a given element will remain the same. See Also Dropout2d Dropout3d",
    "summary" : "Randomly zero a portion of the elements during training.",
    "title" : "Dropout"
  },
  {
    "headings" : [
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/filterAll"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Filter that will accept all values.  See Also Module Filter and Map Functions",
    "summary" : "Filter that will accept all values.",
    "title" : "filterAll"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/isStrictSuperset(of:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from SetAlgebra.isStrictSuperset(of:). ",
    "summary" : "Inherited from SetAlgebra.isStrictSuperset(of:).",
    "title" : "isStrictSuperset(of:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/RoPE\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Evaluate with offset of 0. ",
    "summary" : "Evaluate with offset of 0.",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/isEmpty"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from SetAlgebra.isEmpty. ",
    "summary" : "Inherited from SetAlgebra.isEmpty.",
    "title" : "isEmpty"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/selu(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Scaled Exponential Linear Unit.  Discussion This is:  See Also Activation Functions and Layers SELU elu(_:alpha:)",
    "summary" : "Applies the Scaled Exponential Linear Unit.",
    "title" : "selu(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/intersection(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from OptionSet.intersection(_:). ",
    "summary" : "Inherited from OptionSet.intersection(_:).",
    "title" : "intersection(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/GELU\/Approximation\/precise"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "See geluApproximate(_:) ",
    "summary" : "See geluApproximate(_:)",
    "title" : "GELU.Approximation.precise"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LossReduction\/none"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "take the loss as-is.  This produces an array the same shape as the input. ",
    "summary" : "take the loss as-is.  This produces an array the same shape as the input.",
    "title" : "LossReduction.none"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/logSigmoid(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Log Sigmoid function.  Discussion This is:  See Also Activation Functions and Layers LogSigmoid",
    "summary" : "Applies the Log Sigmoid function.",
    "title" : "logSigmoid(_:)"
  },
  {
    "headings" : [
      "Return Value",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/l1Loss(predictions:targets:reduction:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Computes the L1 loss  the predicted values the target values reduction type Return Value computed L1 loss See Also Loss Functions",
    "summary" : "Computes the L1 loss",
    "title" : "l1Loss(predictions:targets:reduction:)"
  },
  {
    "headings" : [
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/filterValidParameters"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Filter that will accept all structure (.array and .dictionary) and ModuleValue.parameters(_:) or ModuleValue.module(_:) allowing recursion into sub-Modules (layers).  See Also Module Filter and Map Functions filterLocalParameters filterTrainableParameters",
    "summary" : "Filter that will accept all structure (.array and .dictionary) and ModuleValue.parameters(_:) or ModuleValue.module(_:) allowing recursion into sub-Modules (layers).",
    "title" : "filterValidParameters"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/QuantizedLinear\/init(_:_:bias:groupSize:bits:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies an affine transformation to the input using a quantized weight matrix.  number of input dimensions number of output dimensions if true this layer will apply a bias The group size to use for the quantized weight The bit width to use for the quantized weight Discussion This is the quantized version of Linear.  Typically this is used via quantize(model:groupSize:bits:predicate:).",
    "summary" : "Applies an affine transformation to the input using a quantized weight matrix.",
    "title" : "init(_:_:bias:groupSize:bits:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Sequential\/init(layers:)-3zdqn"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(layers:)"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Embedding\/init(embeddingCount:dimensions:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Implements a simple lookup table that maps each input integer to a high-dimensional vector.  How many possible discrete tokens can we embed.  Usually called the vocabulary size. dimensionality of the embeddings. Discussion Typically used to embed discrete tokens for processing by neural networks.",
    "summary" : "Implements a simple lookup table that maps each input integer to a high-dimensional vector.",
    "title" : "init(embeddingCount:dimensions:)"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/update(parameters:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "A non-throwing version of update(parameters:verify:).  Discussion This passes verify: .none.  Note that there may still be fatalErrors() if for example an MLXArray is set on a Module.",
    "summary" : "A non-throwing version of update(parameters:verify:).",
    "title" : "update(parameters:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Dropout2d\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/symmetricDifference(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from OptionSet.symmetricDifference(_:). ",
    "summary" : "Inherited from OptionSet.symmetricDifference(_:).",
    "title" : "symmetricDifference(_:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/describeExtra(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Describe extra parameters.  Discussion This will print a description of ModuleValue.other(_:) ivars, e.g.:  Subclasses can override this to print custom information, e.g. shape information derived from parameters:  See Also description(indent:)",
    "summary" : "Describe extra parameters.",
    "title" : "describeExtra(_:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/QuantizedLinear"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies an affine transformation to the input using a quantized weight matrix.  Overview It is the quantized equivalent of Linear.  For now its parameters are frozen and will not be included in any gradient computation but this will probably change in the future. QuantizedLinear also provides several useful static to convert linear layers to QuantizedLinear layers. from(linear:groupSize:bits:) – returns a QuantizedLinear that applies the same linear transformation up to the quantization error quantize(model:groupSize:bits:predicate:) – swaps all the linear layers of the module with QuantizedLinear ones Please see the disucssion in Linear for considerations when replacing layers. See Also init(weight:bias:groupSize:bits:)",
    "summary" : "Applies an affine transformation to the input using a quantized weight matrix.",
    "title" : "QuantizedLinear"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Embedding\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [
      "Return Value"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/QuantizedLinear\/from(linear:groupSize:bits:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Returns a QuantizedLinear layer that applies the same linear transformation up to the quantization error.  a Linear layer The group size to use for the quantized weight The bit width to use for the quantized weight Return Value a new QuantizedLayer",
    "summary" : "Returns a QuantizedLinear layer that applies the same linear transformation up to the quantization error.",
    "title" : "from(linear:groupSize:bits:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/step(_:threshold:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Step Activation Function.  Discussion This function implements a binary step activation, where the output is set to 1 if the input is greater than a specified threshold, and 0 otherwise. This is:  See Also Activation Functions and Layers Step",
    "summary" : "Applies the Step Activation Function.",
    "title" : "step(_:threshold:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/!=(_:_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from Equatable.!=(_:_:). ",
    "summary" : "Inherited from Equatable.!=(_:_:).",
    "title" : "!=(_:_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/unfreeze(recursive:keys:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Non-throwing variant of unfreeze(recursive:keys:strict:) (strict: false). ",
    "summary" : "Non-throwing variant of unfreeze(recursive:keys:strict:) (strict: false).",
    "title" : "unfreeze(recursive:keys:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/glu(_:axis:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the gated linear unit function.  Discussion This function splits the axis dimension of the input into two halves (a and b) and applies a * sigmoid(b). See Also Activation Functions and Layers GLU",
    "summary" : "Applies the gated linear unit function.",
    "title" : "glu(_:axis:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/prelu(_:alpha:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the element-wise parametric ReLU.  Discussion This is:  See Also Activation Functions and Layers PReLU",
    "summary" : "Applies the element-wise parametric ReLU.",
    "title" : "prelu(_:alpha:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SiLU"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Sigmoid Linear Unit. Also known as Swish.  Overview This is:  See Also Activation Functions and Layers silu(_:)",
    "summary" : "Applies the Sigmoid Linear Unit. Also known as Swish.",
    "title" : "SiLU"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/isDisjoint(with:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from SetAlgebra.isDisjoint(with:). ",
    "summary" : "Inherited from SetAlgebra.isDisjoint(with:).",
    "title" : "isDisjoint(with:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Sigmoid\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ModuleInfo"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "ModuleInfo can provde information about child modules and act as an update point for update(modules:verify:).  Overview The keys for modules and parameters are usually named after their instance variables, but feed_forward would not be a very Swifty variable name:  Instead we can use ModuleInfo to supply a replacement key that matches the python version:  All Linear modules should use a ModuleInfo so that quantize(model:groupSize:bits:predicate:) can replace them at runtime:  The ModuleInfo provides a hook for QuantizedLinear and update(modules:verify:) \/\/\/ to replace the contents of w1, etc. with a new compatible Model after it is created. See Also Creating Modules ParameterInfo",
    "summary" : "ModuleInfo can provde information about child modules and act as an update point for update(modules:verify:).",
    "title" : "ModuleInfo"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/insert(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from OptionSet.insert(_:). ",
    "summary" : "Inherited from OptionSet.insert(_:).",
    "title" : "insert(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Dropout\/init(p:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(p:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/description(indent:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from IndentedDescription.description(indent:). ",
    "summary" : "Inherited from IndentedDescription.description(indent:).",
    "title" : "description(indent:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/UnaryLayer\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [
      "Return Value",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/mseLoss(predictions:targets:reduction:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Computes the mean squared error loss.  the predicted values the target values reduction type Return Value computed mean squared error loss See Also Loss Functions",
    "summary" : "Computes the mean squared error loss.",
    "title" : "mseLoss(predictions:targets:reduction:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SequentialBuilder\/buildOptional(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "buildOptional(_:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/mish(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Mish function, element-wise.  Discussion Mish: A Self Regularized Non-Monotonic Neural Activation Function. Reference: https:\/\/arxiv.org\/abs\/1908.08681 This is:  See Also Activation Functions and Layers Mish",
    "summary" : "Applies the Mish function, element-wise.",
    "title" : "mish(_:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ParameterInfo"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "ParameterInfo allows you to specify alternate keys for parameter propreties.  Overview For example:  will have keys weights and bias. See Also Creating Modules ModuleInfo",
    "summary" : "ParameterInfo allows you to specify alternate keys for parameter propreties.",
    "title" : "ParameterInfo"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/GELU\/Approximation"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "GELU.Approximation"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/rawValue"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from RawRepresentable.rawValue. ",
    "summary" : "Inherited from RawRepresentable.rawValue.",
    "title" : "rawValue"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/isLeafDefault"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Default leaf filter – treat ModuleValue.parameters(_:) and ModuleValue.other(_:) as leaves.  Discussion This will allow recursion into .array, .dictionary and ModuleValue.module(_:). See Also Module Filter and Map Functions filterMap(filter:map:isLeaf:)",
    "summary" : "Default leaf filter – treat ModuleValue.parameters(_:) and ModuleValue.other(_:) as leaves.",
    "title" : "isLeafDefault"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Conv1d\/init(inputChannels:outputChannels:kernelSize:stride:padding:bias:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies a 1-dimensional convolution over the multi-channel input sequence.  number of input channels (C from the discussion) number of output channels size of the convolution filters stride when applying the filter many positions to 0-pad the input with if true add a learnable bias to the output Discussion The channels are expected to be last i.e. the input shape should be NLC where: N is the batch dimension L is the sequence length C is the number of input channels",
    "summary" : "Applies a 1-dimensional convolution over the multi-channel input sequence.",
    "title" : "init(inputChannels:outputChannels:kernelSize:stride:padding:bias:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LossReduction\/init(rawValue:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from RawRepresentable.init(rawValue:). ",
    "summary" : "Inherited from RawRepresentable.init(rawValue:).",
    "title" : "init(rawValue:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/UnaryLayer"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "A Layer (Module subclass) that can be evaluated as a unary function.  Overview This provides callAsFunction(_:) with a single MLXArray input and a single MLXArray output. See Also Layers Sequential",
    "summary" : "A Layer (Module subclass) that can be evaluated as a unary function.",
    "title" : "UnaryLayer"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/sigmoid(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the element-wise logistic sigmoid.  Discussion For details, please see this documentation This is:  See Also Activation Functions and Layers Sigmoid",
    "summary" : "Applies the element-wise logistic sigmoid.",
    "title" : "sigmoid(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/init(arrayLiteral:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from SetAlgebra.init(arrayLiteral:). ",
    "summary" : "Inherited from SetAlgebra.init(arrayLiteral:).",
    "title" : "init(arrayLiteral:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/RMSNorm\/describeExtra(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Describe dimensions and eps. ",
    "summary" : "Describe dimensions and eps.",
    "title" : "describeExtra(_:)"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/trainableParameters()"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Return a NestedDictionary<String, MLXArray> for all trainable parameters in the model (all layers).  Discussion This omits freeze(recursive:keys:strict:) (frozen) parameters.",
    "summary" : "Return a NestedDictionary<String, MLXArray> for all trainable parameters in the model (all layers).",
    "title" : "trainableParameters()"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SELU"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Scaled Exponential Linear Unit.  Overview This is:  See Also Activation Functions and Layers selu(_:)",
    "summary" : "Applies the Scaled Exponential Linear Unit.",
    "title" : "SELU"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/subtracting(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from SetAlgebra.subtracting(_:). ",
    "summary" : "Inherited from SetAlgebra.subtracting(_:).",
    "title" : "subtracting(_:)"
  },
  {
    "headings" : [
      "Overview",
      "Examples"
    ],
    "kind" : "article",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/module-filters"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Pre-built filter and map functions in Module. Overview Module provides a number of pre-build filter and map functions for use in: filterMap(filter:map:isLeaf:) apply(filter:map:) mapParameters(map:isLeaf:) See those methods for more information. Examples The filterMap() method has several options for controlling the traversal of the modules, parameters and other values in the model.  Here is an example that limits the traversal to just local parameters and produces a NestedDictionary of the shapes:  Applying a map to the entire set of parameters (though some traversal control is possible through the optional isLeaf) is very easy:  Finally, apply() does both a filter and an update(parameters:). This code would convert all floating point parameters to .float16. ",
    "summary" : "Pre-built filter and map functions in Module.",
    "title" : "Module Filter and Map Functions"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/mapParameters(map:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Function that will turn a (MLXArray) -> Result? into a function suitable for use in filterMap(filter:map:isLeaf:).  Discussion  This is also trivially done with mapParameters(map:isLeaf:), which uses this function internally:  See Also Module Filter and Map Functions ModuleValue.parameters(_:) mapParameters(map:isLeaf:) filterMap(filter:map:isLeaf:)",
    "summary" : "Function that will turn a (MLXArray) -> Result? into a function suitable for use in filterMap(filter:map:isLeaf:).",
    "title" : "mapParameters(map:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SELU\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LossReduction\/!=(_:_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from Equatable.!=(_:_:). ",
    "summary" : "Inherited from Equatable.!=(_:_:).",
    "title" : "!=(_:_:)"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ModuleValue\/fromMirror(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Return (String, ModuleItem) tuple or nil if the label cannot be determined.  Discussion Called from items()",
    "summary" : "Return (String, ModuleItem) tuple or nil if the label cannot be determined.",
    "title" : "fromMirror(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/MultiHeadAttention"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "MultiHeadAttention"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Tanh"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the hyperbolic tangent function ",
    "summary" : "Applies the hyperbolic tangent function",
    "title" : "Tanh"
  },
  {
    "headings" : [
      "Return Value",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/hingeLoss(inputs:targets:reduction:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Computes the hinge loss between inputs and targets.  predicted values target values: -1 or 1 reduction type Return Value computed hinge loss See Also Loss Functions",
    "summary" : "Computes the hinge loss between inputs and targets.",
    "title" : "hingeLoss(inputs:targets:reduction:)"
  },
  {
    "headings" : [
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Conv1d"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies a 1-dimensional convolution over the multi-channel input sequence.  See Also Conv2d init(inputChannels:outputChannels:kernelSize:stride:padding:bias:)",
    "summary" : "Applies a 1-dimensional convolution over the multi-channel input sequence.",
    "title" : "Conv1d"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ModuleParameters"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "NestedDictionary structure of MLXArray ",
    "summary" : "NestedDictionary structure of MLXArray",
    "title" : "ModuleParameters"
  },
  {
    "headings" : [
      "Return Value",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/tripletLoss(anchors:positives:negatives:axis:p:margin:eps:reduction:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Computes the triplet loss for a set of anchor, positive, and negative samples. Margin is represented with alpha in the math section.  anchor samples positive samples negative samples distribution axis norm dree for pairwise distance margin for the triplet loss small positive constant to prevent numerical instability reduction type Return Value Computed triplet loss. See Also Loss Functions",
    "summary" : "Computes the triplet loss for a set of anchor, positive, and negative samples. Margin is represented with alpha in the math section.",
    "title" : "tripletLoss(anchors:positives:negatives:axis:p:margin:eps:reduction:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Dropout3d\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/RMSNorm"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies Root Mean Square normalization [1] to the inputs.  Overview Concretely:  See Also https:\/\/arxiv.org\/abs\/1910.07467",
    "summary" : "Applies Root Mean Square normalization [1] to the inputs.",
    "title" : "RMSNorm"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/MultiHeadAttention\/init(dimensions:numHeads:queryInputDimensions:keyInputDimensions:valueInputDimensions:valueDimensions:valueOutputDimensions:bias:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(dimensions:numHeads:queryInputDimensions:keyInputDimensions:valueInputDimensions:valueDimensions:valueOutputDimensions:bias:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/relu6(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Rectified Linear Unit 6.  Discussion This is:  See Also Activation Functions and Layers Relu6",
    "summary" : "Applies the Rectified Linear Unit 6.",
    "title" : "relu6(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/RMSNorm\/init(_:eps:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(_:eps:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/isSubset(of:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from SetAlgebra.isSubset(of:). ",
    "summary" : "Inherited from SetAlgebra.isSubset(of:).",
    "title" : "isSubset(of:)"
  },
  {
    "headings" : [
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/filterOther"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Filter that will accept all structure (.array and .dictionary) and ModuleValue.other(_:).  See Also Module Filter and Map Functions",
    "summary" : "Filter that will accept all structure (.array and .dictionary) and ModuleValue.other(_:).",
    "title" : "filterOther"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SoftMax"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Softmax function.  Overview This is:  See Also Activation Functions and Layers softMax(_:)",
    "summary" : "Applies the Softmax function.",
    "title" : "SoftMax"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SequentialBuilder\/buildExpression(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "buildExpression(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LossReduction\/reduce(loss:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "reduce(loss:)"
  },
  {
    "headings" : [
      "Return Value",
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/logCoshLoss(inputs:targets:reduction:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Computes the log cosh loss between inputs and targets.  predicted values target values reduction type Return Value computed log cosh loss Discussion Logcosh acts like L2 loss for small errors, ensuring stable gradients, and like the L1 loss for large errors, reducing sensitivity to outliers. This dual behavior offers a balanced, robust approach for regression tasks. See Also Loss Functions",
    "summary" : "Computes the log cosh loss between inputs and targets.",
    "title" : "logCoshLoss(inputs:targets:reduction:)"
  },
  {
    "headings" : [
      "Return Value",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/huberLoss(inputs:targets:delta:reduction:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Computes the Huber loss between inputs and targets.  predicted values target values threshold at which to change between L1 and L2 loss reduction type Return Value computed Huber loss See Also Loss Functions",
    "summary" : "Computes the Huber loss between inputs and targets.",
    "title" : "huberLoss(inputs:targets:delta:reduction:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/QuantizedLinear\/init(weight:bias:groupSize:bits:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(weight:bias:groupSize:bits:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/PReLU"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the element-wise parametric ReLU.  Overview This is:  See Also Activation Functions and Layers prelu(_:alpha:)",
    "summary" : "Applies the element-wise parametric ReLU.",
    "title" : "PReLU"
  },
  {
    "headings" : [
      "Overview"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Sequential"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "A layer that calls the passed UnaryLayer in order.  Overview Sequential can be constructed either with an array of layers or using a SequentialBuilder:  produces: ",
    "summary" : "A layer that calls the passed UnaryLayer in order.",
    "title" : "Sequential"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/description"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from IndentedDescription.description. ",
    "summary" : "Inherited from IndentedDescription.description.",
    "title" : "description"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ModuleValue\/parameters(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "An MLXArray parameters value.  Discussion From code: ",
    "summary" : "An MLXArray parameters value.",
    "title" : "ModuleValue.parameters(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/formIntersection(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from OptionSet.formIntersection(_:). ",
    "summary" : "Inherited from OptionSet.formIntersection(_:).",
    "title" : "formIntersection(_:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Dropout2d"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Apply 2D channel-wise dropout during training.  Overview Randomly zero out entire channels independently with probability p. This layer expects the channels to be last, i.e. the input shape should be NWHC or WHC where:N is the batch dimension,H is the input image height,W is the input image width, andC is the number of input channels The remaining channels are scaled by 1 \/ (1-p) to maintain the expected value of each element. Unlike traditional dropout, which zeros individual entries, this layer zeros entire channels. This is beneficial for early convolution layers where adjacent pixels are correlated. In such case, traditional dropout may not effectively regularize activations. For more details, see [1]. [1]: Thompson, J., Goroshin, R., Jain, A., LeCun, Y. and Bregler C., 2015. Efficient Object Localization Using Convolutional Networks. CVPR 2015. See Also Dropout Dropout3d",
    "summary" : "Apply 2D channel-wise dropout during training.",
    "title" : "Dropout2d"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/unfreeze(recursive:keys:strict:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Unfreeze the Module’s parameters or subset.  if true this will unfreeze the parameters of child Module recursively optional keys to unfreeze – if unspecified, will apply to all if true validate that the passed keys exist Discussion A frozen parameter does not compute gradients.  The function is idempotent – unfreezing a frozen model is a no-op. For instance to only train the biases of a Transformer one can do:  See Also freeze(recursive:keys:) unfreeze(recursive:keys:strict:)",
    "summary" : "Unfreeze the Module’s parameters or subset.",
    "title" : "unfreeze(recursive:keys:strict:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/mapModule(map:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Function that will turn a (Module) -> Result? into a function suitable for use in filterMap(filter:map:isLeaf:).  Discussion For example:  See Also Module Filter and Map Functions ModuleValue.module(_:) filterMap(filter:map:isLeaf:)",
    "summary" : "Function that will turn a (Module) -> Result? into a function suitable for use in filterMap(filter:map:isLeaf:).",
    "title" : "mapModule(map:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/freeze(recursive:keys:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Non-throwing variant of freeze(recursive:keys:strict:) (strict: false). ",
    "summary" : "Non-throwing variant of freeze(recursive:keys:strict:) (strict: false).",
    "title" : "freeze(recursive:keys:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Sigmoid"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the element-wise logistic sigmoid.  Overview For details, please see this documentation This is:  See Also Activation Functions and Layers sigmoid(_:)",
    "summary" : "Applies the element-wise logistic sigmoid.",
    "title" : "Sigmoid"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LossReduction"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Different types of loss reductions ",
    "summary" : "Different types of loss reductions",
    "title" : "LossReduction"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Conv2d\/init(inputChannels:outputChannels:kernelSize:stride:padding:bias:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies a 2-dimensional convolution over the multi-channel input image.  number of input channels (C from the discussion) number of output channels size of the convolution filters stride when applying the filter many positions to 0-pad the input with if true add a learnable bias to the output Discussion The channels are expected to be last i.e. the input shape should be NHWC where: N is the batch dimension H is the input image height W is the input image width C is the number of input channels",
    "summary" : "Applies a 2-dimensional convolution over the multi-channel input image.",
    "title" : "init(inputChannels:outputChannels:kernelSize:stride:padding:bias:)"
  },
  {
    "headings" : [
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/modules()"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Return a flat array of all the Module in the instance (including self).  See Also namedModules() children() leafModules()",
    "summary" : "Return a flat array of all the Module in the instance (including self).",
    "title" : "modules()"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/softSign(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Softsign function.  Discussion This is:  See Also Activation Functions and Layers SoftSign",
    "summary" : "Applies the Softsign function.",
    "title" : "softSign(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/formSymmetricDifference(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from OptionSet.formSymmetricDifference(_:). ",
    "summary" : "Inherited from OptionSet.formSymmetricDifference(_:).",
    "title" : "formSymmetricDifference(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SoftPlus\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/GELU\/init(approximation:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(approximation:)"
  },
  {
    "headings" : [

    ],
    "kind" : "article",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/Equatable-Implementations"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "",
    "summary" : "",
    "title" : "Equatable Implementations"
  },
  {
    "headings" : [

    ],
    "kind" : "article",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LossReduction\/RawRepresentable-Implementations"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "",
    "summary" : "",
    "title" : "RawRepresentable Implementations"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SoftPlus"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Softplus function.  Overview This is:  See Also Activation Functions and Layers softPlus(_:)",
    "summary" : "Applies the Softplus function.",
    "title" : "SoftPlus"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Step"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Step Activation Function.  Overview This function implements a binary step activation, where the output is set to 1 if the input is greater than a specified threshold, and 0 otherwise. This is:  See Also Activation Functions and Layers step(_:threshold:)",
    "summary" : "Applies the Step Activation Function.",
    "title" : "Step"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Bilinear\/describeExtra(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Describe the inputDimensions and outputDimensions. ",
    "summary" : "Describe the inputDimensions and outputDimensions.",
    "title" : "describeExtra(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SequentialBuilder\/buildPartialBlock(accumulated:next:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "buildPartialBlock(accumulated:next:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/LogSoftMax"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Log Softmax function.  Overview This is:  See Also Activation Functions and Layers logSoftMax(_:axis:)",
    "summary" : "Applies the Log Softmax function.",
    "title" : "LogSoftMax"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ModuleChilren"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "NestedDictionary structure of Module ",
    "summary" : "NestedDictionary structure of Module",
    "title" : "ModuleChilren"
  },
  {
    "headings" : [

    ],
    "kind" : "article",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/OptionSet-Implementations"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "",
    "summary" : "",
    "title" : "OptionSet Implementations"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Linear\/init(_:_:bias:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies an affine transformation to the input.  number of input dimensions number of output dimensions if true this layer will apply a bias Discussion Please see discussion in Module.",
    "summary" : "Applies an affine transformation to the input.",
    "title" : "init(_:_:bias:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/geluFastApproximate(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "A fast approximation to Gaussian Error Linear Unit.  Discussion This is:  See Also Activation Functions and Layers GELU gelu(_:) geluApproximate(_:)",
    "summary" : "A fast approximation to Gaussian Error Linear Unit.",
    "title" : "geluFastApproximate(_:)"
  },
  {
    "headings" : [
      "Overview"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/RoPE"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Implements the rotary positional encoding.  Overview The traditional implementation rotates consecutive pairs of elements in the feature dimension while the default implementation rotates pairs with stride half the feature dimensions for efficiency. For more details see RoFormer: Enhanced Transformer with Rotary Position Embedding (https:\/\/arxiv.org\/abs\/2104.09864)",
    "summary" : "Implements the rotary positional encoding.",
    "title" : "RoPE"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ModuleValue\/other(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "A non-MLXArray and non-Module value.  Discussion From code: ",
    "summary" : "A non-MLXArray and non-Module value.",
    "title" : "ModuleValue.other(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "article",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/IndentedDescription-Implementations"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "",
    "summary" : "",
    "title" : "IndentedDescription Implementations"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/PReLU\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Dropout2d\/init(p:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(p:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/remove(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from OptionSet.remove(_:). ",
    "summary" : "Inherited from OptionSet.remove(_:).",
    "title" : "remove(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SequentialBuilder\/buildEither(first:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "buildEither(first:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SiLU\/callAsFunction(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Inherited from UnaryLayer.callAsFunction(_:). ",
    "summary" : "Inherited from UnaryLayer.callAsFunction(_:).",
    "title" : "callAsFunction(_:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/train(mode:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Recursively set the model’s training mode.  Discussion Training mode only applies to certain layers. For example Dropout applies a random mask in training mode, but is the identity in evaluation mode. See Also training",
    "summary" : "Recursively set the model’s training mode.",
    "title" : "train(mode:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Options for verifying update(parameters:verify:) and update(modules:verify:). ",
    "summary" : "Options for verifying update(parameters:verify:) and update(modules:verify:).",
    "title" : "Module.VerifyUpdate"
  },
  {
    "headings" : [
      "Return Value",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/binaryCrossEntropy(logits:targets:reduction:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Computes the binary cross entropy loss.  unnormalized predicted logits binary target values in {0, 1} reduction type Return Value computed binary cross entropy loss See Also Loss Functions",
    "summary" : "Computes the binary cross entropy loss.",
    "title" : "binaryCrossEntropy(logits:targets:reduction:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/SequentialBuilder\/buildArray(_:)-876fs"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "buildArray(_:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Dropout3d"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Apply 3D channel-wise dropout during training.  Overview Randomly zero out entire channels independently with probability p. This layer expects the channels to be last, i.e., the input shape should be NDHWC or DHWC where: N is the batch dimension, D is the depth, H is the input image height, W is the input image width, and C is the number of input channels. The remaining channels are scaled by 1 \/ (1-p) to maintain the expected value of each element. Unlike traditional dropout, which zeros individual entries, this layer zeros entire channels. This is often beneficial for convolutional layers processing 3D data, like in medical imaging or video processing. See Also Dropout Dropout2d",
    "summary" : "Apply 3D channel-wise dropout during training.",
    "title" : "Dropout3d"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/hardSwish(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the hardswish function, element-wise  Discussion This is:  See Also Activation Functions and Layers HardSwish",
    "summary" : "Applies the hardswish function, element-wise",
    "title" : "hardSwish(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/visit(modules:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "visit(modules:)"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/gelu(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Gaussian Error Linear Units function.  Discussion This is:  See Also Activation Functions and Layers GELU geluApproximate(_:) geluFastApproximate(_:)",
    "summary" : "Applies the Gaussian Error Linear Units function.",
    "title" : "gelu(_:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/init()"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init()"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/RoPE\/callAsFunction(_:offset:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "callAsFunction(_:offset:)"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/update(modules:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "A non-throwing version of update(modules:verify:).  Discussion This passes verify: .none.  Note that there may still be fatalErrors() if for example an Module is set on a MLXArray.",
    "summary" : "A non-throwing version of update(modules:verify:).",
    "title" : "update(modules:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/children()"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Produces a NestedDictionary<String, Module> for all direct children of the module. ",
    "summary" : "Produces a NestedDictionary<String, Module> for all direct children of the module.",
    "title" : "children()"
  },
  {
    "headings" : [
      "Discussion",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/leakyRelu(_:negativeSlope:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the Leaky Rectified Linear Unit.  Discussion This is:  See Also Activation Functions and Layers LeakyReLU",
    "summary" : "Applies the Leaky Rectified Linear Unit.",
    "title" : "leakyRelu(_:negativeSlope:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Step\/init(threshold:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "init(threshold:)"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Linear\/describeExtra(_:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Describe the inputDimensions and outputDimensions. ",
    "summary" : "Describe the inputDimensions and outputDimensions.",
    "title" : "describeExtra(_:)"
  },
  {
    "headings" : [
      "Overview",
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/GLU"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Applies the gated linear unit function.  Overview This function splits the axis dimension of the input into two halves (a and b) and applies a * sigmoid(b). See Also Activation Functions and Layers glu(_:axis:)",
    "summary" : "Applies the gated linear unit function.",
    "title" : "GLU"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Identity"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "A placeholder identity operator that is argument-insensitive. ",
    "summary" : "A placeholder identity operator that is argument-insensitive.",
    "title" : "Identity"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/VerifyUpdate\/none"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " ",
    "summary" : "",
    "title" : "none"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/QuantizedLinear\/quantize(model:groupSize:bits:predicate:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Replace Linear layers with QuantizedLinear.  the model to update The group size to use for the quantized weight The bit width to use for the quantized weight optional predicate for identifying layers to change – default finds all Linear layers Discussion Please see the disucssion in Linear for considerations when replacing layers.",
    "summary" : "Replace Linear layers with QuantizedLinear.",
    "title" : "quantize(model:groupSize:bits:predicate:)"
  },
  {
    "headings" : [
      "See Also"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/leafModules()"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Produces a NestedDictionary<String, Module> for all leaf modules module.  See Also isLeafModuleNoChildren",
    "summary" : "Produces a NestedDictionary<String, Module> for all leaf modules module.",
    "title" : "leafModules()"
  },
  {
    "headings" : [
      "Discussion"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/Module\/apply(filter:map:)"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Apply a closure to the parameters in a Module recursively.  filter for parameters to apply to function to apply to the matched parameters Discussion For example to change all floating point parameters to DType.float16: ",
    "summary" : "Apply a closure to the parameters in a Module recursively.",
    "title" : "apply(filter:map:)"
  },
  {
    "headings" : [
      "Overview",
      "Other MLX Packages"
    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : " Overview Some places to read to get started are: Module Creating Modules Training a Model Other MLX Packages MLX MLXRandom MLXOptimizers Python mlx",
    "summary" : "",
    "title" : "MLXNN"
  },
  {
    "headings" : [

    ],
    "kind" : "symbol",
    "location" : {
      "reference" : {
        "interfaceLanguage" : "swift",
        "url" : "doc:\/\/mlx.swift.mlxnn\/documentation\/MLXNN\/ModuleItem"
      },
      "type" : "topLevelPage"
    },
    "rawIndexableTextContent" : "Single item from items() ",
    "summary" : "Single item from items()",
    "title" : "ModuleItem"
  }
]